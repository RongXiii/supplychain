import sys
import os
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.ab_testing import TestVariant, ABTestManager

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°
np.random.seed(42)

def test_ab_testing_framework():
    """æµ‹è¯•A/Bæµ‹è¯•æ¡†æ¶çš„æ ¸å¿ƒåŠŸèƒ½"""
    print("=== å¼€å§‹æµ‹è¯•A/Bæµ‹è¯•æ¡†æ¶ ===")
    
    # 1. åˆ›å»ºA/Bæµ‹è¯•ç®¡ç†å™¨
    test_manager = ABTestManager(test_id="test_demo_001")
    print(f"âœ“ åˆ›å»ºæµ‹è¯•ç®¡ç†å™¨ï¼Œæµ‹è¯•ID: {test_manager.test_id}")
    
    # 2. åˆ›å»ºæµ‹è¯•å˜ä½“
    # å˜ä½“Aï¼šåŸºçº¿æ¨¡å‹
    variant_a = TestVariant(variant_id="A", name="Baseline Model", sample_size=1000)
    # å˜ä½“Bï¼šæ–°æ¨¡å‹1
    variant_b = TestVariant(variant_id="B", name="New Model 1", sample_size=1000)
    # å˜ä½“Cï¼šæ–°æ¨¡å‹2
    variant_c = TestVariant(variant_id="C", name="New Model 2", sample_size=1000)
    
    # æ·»åŠ å˜ä½“ä¼šæµ‹è¯•ç®¡ç†å™¨
    test_manager.add_variant(variant_a)
    test_manager.add_variant(variant_b)
    test_manager.add_variant(variant_c)
    print(f"âœ“ åˆ›å»ºå¹¶æ·»åŠ äº† {len(test_manager.variants)} ä¸ªæµ‹è¯•å˜ä½“")
    
    # 3. è®¾ç½®æµ‹è¯•æŒ‡æ ‡
    metrics = ["conversion_rate", "revenue_per_user", "click_through_rate", "average_order_value"]
    test_manager.set_metrics(metrics)
    print(f"âœ“ è®¾ç½®äº†æµ‹è¯•æŒ‡æ ‡: {', '.join(metrics)}")
    
    # 4. å¼€å§‹æµ‹è¯•
    test_manager.start_test()
    print(f"âœ“ æµ‹è¯•å¼€å§‹æ—¶é—´: {test_manager.start_time}")
    
    # 5. æ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
    print("\n=== æ¨¡æ‹Ÿæµ‹è¯•æ•°æ® ===")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®çš„å‚æ•°
    # å˜ä½“Aï¼ˆåŸºçº¿ï¼‰
    params_a = {
        "conversion_rate": (0.10, 0.02),  # å‡å€¼, æ ‡å‡†å·®
        "revenue_per_user": (50, 10),
        "click_through_rate": (0.05, 0.01),
        "average_order_value": (100, 20)
    }
    
    # å˜ä½“Bï¼ˆæ–°æ¨¡å‹1ï¼Œæ€§èƒ½ç¨å¥½ï¼‰
    params_b = {
        "conversion_rate": (0.12, 0.02),
        "revenue_per_user": (55, 11),
        "click_through_rate": (0.06, 0.012),
        "average_order_value": (105, 22)
    }
    
    # å˜ä½“Cï¼ˆæ–°æ¨¡å‹2ï¼Œæ€§èƒ½æœ€å¥½ï¼‰
    params_c = {
        "conversion_rate": (0.15, 0.025),
        "revenue_per_user": (60, 12),
        "click_through_rate": (0.08, 0.015),
        "average_order_value": (115, 25)
    }
    
    # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå‡½æ•°
    def generate_performance_data(params, n_samples=1000):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ€§èƒ½æ•°æ®"""
        data = []
        for _ in range(n_samples):
            record = {}
            for metric, (mean, std) in params.items():
                # ç”Ÿæˆæ­£æ€åˆ†å¸ƒæ•°æ®ï¼Œç¡®ä¿éè´Ÿ
                value = np.max([0, np.random.normal(mean, std)])
                record[metric] = value
            data.append(record)
        return data
    
    # ä¸ºæ¯ä¸ªå˜ä½“ç”Ÿæˆæ•°æ®
    data_a = generate_performance_data(params_a, 1000)
    data_b = generate_performance_data(params_b, 1000)
    data_c = generate_performance_data(params_c, 1000)
    
    # è®°å½•æ€§èƒ½æ•°æ®
    for record in data_a:
        variant_a.record_performance(**record)
    
    for record in data_b:
        variant_b.record_performance(**record)
    
    for record in data_c:
        variant_c.record_performance(**record)
    
    print(f"âœ“ ä¸ºå˜ä½“Aç”Ÿæˆäº† {len(data_a)} æ¡æ•°æ®")
    print(f"âœ“ ä¸ºå˜ä½“Bç”Ÿæˆäº† {len(data_b)} æ¡æ•°æ®")
    print(f"âœ“ ä¸ºå˜ä½“Cç”Ÿæˆäº† {len(data_c)} æ¡æ•°æ®")
    
    # 6. ç»“æŸæµ‹è¯•
    test_manager.end_test()
    print(f"\nâœ“ æµ‹è¯•ç»“æŸæ—¶é—´: {test_manager.end_time}")
    print(f"âœ“ æµ‹è¯•æŒç»­æ—¶é—´: {test_manager.end_time - test_manager.start_time}")
    
    # 7. è®¡ç®—å˜ä½“æŒ‡æ ‡
    for variant in test_manager.variants.values():
        print(f"\n=== å˜ä½“ {variant.name} æŒ‡æ ‡ ===")
        for metric, stats in variant.metrics.items():
            print(f"  {metric}: å‡å€¼={stats['mean']:.4f}, æ ‡å‡†å·®={stats['std']:.4f}, æ ·æœ¬é‡={stats['count']}")
    
    # 8. è¿è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•
    print("\n=== è¿è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯• ===")
    test_manager.run_statistical_tests(alpha=0.05)
    print(f"âœ“ å®Œæˆäº† {len(test_manager.test_results)} æ¬¡ç»Ÿè®¡æ¯”è¾ƒ")
    
    # 9. æ˜¾ç¤ºç»Ÿè®¡æµ‹è¯•ç»“æœ
    print("\n=== ç»Ÿè®¡æµ‹è¯•ç»“æœæ‘˜è¦ ===")
    for key, result in test_manager.test_results.items():
        # å…ˆåˆ†å‰²å‡ºå˜ä½“éƒ¨åˆ†å’ŒæŒ‡æ ‡éƒ¨åˆ†
        parts = key.split('_vs_')
        variant_a_id = parts[0]
        # å‰©ä½™éƒ¨åˆ†åŒ…å« variant_b_id å’Œ metricï¼Œä¾‹å¦‚ "B_conversion_rate"
        variant_b_and_metric = '_vs_'.join(parts[1:])
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿ï¼Œåˆ†å‰²å‡º variant_b_id å’Œ metric
        first_underscore_index = variant_b_and_metric.find('_')
        variant_b_id = variant_b_and_metric[:first_underscore_index]
        metric = variant_b_and_metric[first_underscore_index+1:]
        
        variant_a_name = test_manager.variants[variant_a_id].name
        variant_b_name = test_manager.variants[variant_b_id].name
        
        sig_text = "æ˜¾è‘—" if result['significant'] else "ä¸æ˜¾è‘—"
        print(f"  {variant_a_name} vs {variant_b_name} ({metric}): på€¼={result['p_value']:.4f}, {sig_text}")
    
    # 10. ç”Ÿæˆå¯è§†åŒ–
    print("\n=== ç”Ÿæˆæµ‹è¯•å¯è§†åŒ– ===")
    test_manager.generate_visualizations()
    print(f"âœ“ å¯è§†åŒ–å·²ç”Ÿæˆï¼Œä¿å­˜åœ¨: {test_manager.visualizer.output_dir}")
    
    # 11. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print("\n=== ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š ===")
    report_path = test_manager.generate_report()
    print(f"âœ“ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    # 12. è·å–æµ‹è¯•æ‘˜è¦
    test_summary = test_manager.get_test_summary()
    print("\n=== æµ‹è¯•æ‘˜è¦ ===")
    for key, value in test_summary.items():
        print(f"  {key}: {value}")
    
    print("\n=== A/Bæµ‹è¯•æ¡†æ¶æµ‹è¯•å®Œæˆ ===")
    print(f"âœ“ æµ‹è¯•ç»“æœæ˜¾ç¤ºï¼šåœ¨{len(test_manager.test_results)}æ¬¡æ¯”è¾ƒä¸­ï¼Œæœ‰{test_summary['num_significant_results']}æ¬¡ç»“æœå…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§")
    
    # æ£€æŸ¥æµ‹è¯•ç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
    # é¢„æœŸï¼šå˜ä½“Cåº”è¯¥åœ¨å¤§å¤šæ•°æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºå˜ä½“Aå’ŒB
    significant_results = [r for r in test_manager.test_results.values() if r['significant']]
    assert len(significant_results) > 0, "åº”è¯¥æœ‰æ˜¾è‘—çš„æµ‹è¯•ç»“æœ"
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼A/Bæµ‹è¯•æ¡†æ¶åŠŸèƒ½æ­£å¸¸")
    
    return True

def test_variant_assignment():
    """æµ‹è¯•å˜ä½“åˆ†é…åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å˜ä½“åˆ†é…åŠŸèƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•ç®¡ç†å™¨
    test_manager = ABTestManager()
    
    # åˆ›å»ºæµ‹è¯•å˜ä½“
    variant_a = TestVariant(variant_id="A", name="Variant A")
    variant_b = TestVariant(variant_id="B", name="Variant B")
    variant_c = TestVariant(variant_id="C", name="Variant C")
    
    test_manager.add_variant(variant_a)
    test_manager.add_variant(variant_b)
    test_manager.add_variant(variant_c)
    
    # æµ‹è¯•åˆ†é…ç¨³å®šæ€§ï¼šç›¸åŒç”¨æˆ·IDåº”è¯¥åˆ†é…åˆ°ç›¸åŒå˜ä½“
    user_ids = ["user_123", "user_456", "user_789", "user_101", "user_202"]
    
    for user_id in user_ids:
        variant1 = test_manager.assign_variant(user_id)
        variant2 = test_manager.assign_variant(user_id)
        assert variant1.variant_id == variant2.variant_id, f"ç”¨æˆ· {user_id} åº”è¯¥åˆ†é…åˆ°ç›¸åŒå˜ä½“"
        print(f"  ç”¨æˆ· {user_id} ç¨³å®šåˆ†é…åˆ°å˜ä½“: {variant1.name}")
    
    # æµ‹è¯•åˆ†é…å‡åŒ€æ€§
    assignments = {}
    for i in range(10000):
        user_id = f"user_{i}"
        variant = test_manager.assign_variant(user_id)
        assignments[variant.variant_id] = assignments.get(variant.variant_id, 0) + 1
    
    print(f"\n  10,000æ¬¡åˆ†é…ç»“æœï¼š")
    for variant_id, count in assignments.items():
        percentage = count / 10000 * 100
        print(f"    å˜ä½“ {test_manager.variants[variant_id].name}: {count}æ¬¡ ({percentage:.1f}%)")
    
    # éªŒè¯åˆ†é…æ˜¯å¦å¤§è‡´å‡åŒ€ï¼ˆæ¯ä¸ªå˜ä½“åˆ†é…æ¯”ä¾‹åœ¨30%-40%ä¹‹é—´ï¼‰
    for count in assignments.values():
        percentage = count / 10000 * 100
        assert 30 < percentage < 40, f"å˜ä½“åˆ†é…åº”è¯¥å¤§è‡´å‡åŒ€ï¼Œå½“å‰ç™¾åˆ†æ¯”: {percentage:.1f}%"
    
    print("âœ… å˜ä½“åˆ†é…åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
    return True

if __name__ == "__main__":
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    try:
        # æµ‹è¯•A/Bæµ‹è¯•æ¡†æ¶æ ¸å¿ƒåŠŸèƒ½
        test_ab_testing_framework()
        
        # æµ‹è¯•å˜ä½“åˆ†é…åŠŸèƒ½
        test_variant_assignment()
        
        print("\nğŸ‰ æ‰€æœ‰A/Bæµ‹è¯•æ¡†æ¶æµ‹è¯•éƒ½å·²é€šè¿‡ï¼")
        print("\nğŸ“‹ æµ‹è¯•ç»“æœï¼š")
        print("   - æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•: âœ“ é€šè¿‡")
        print("   - å˜ä½“åˆ†é…æµ‹è¯•: âœ“ é€šè¿‡")
        print("   - ç»Ÿè®¡æµ‹è¯•åŠŸèƒ½: âœ“ é€šè¿‡")
        print("   - å¯è§†åŒ–ç”Ÿæˆ: âœ“ é€šè¿‡")
        print("   - æŠ¥å‘Šç”Ÿæˆ: âœ“ é€šè¿‡")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
